{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b1d0631",
   "metadata": {},
   "source": [
    "# データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c478c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from util import CategoriesReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8538e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./train_videos_resized/train_00.mp4', './train_videos_resized/train_01.mp4', './train_videos_resized/train_02.mp4', './train_videos_resized/train_03.mp4', './train_videos_resized/train_04.mp4', './train_videos_resized/train_05.mp4', './train_videos_resized/train_06.mp4', './train_videos_resized/train_07.mp4', './train_videos_resized/train_08.mp4', './train_videos_resized/train_09.mp4', './train_videos_resized/train_10.mp4', './train_videos_resized/train_11.mp4', './train_videos_resized/train_12.mp4', './train_videos_resized/train_13.mp4', './train_videos_resized/train_14.mp4', './train_videos_resized/train_15.mp4', './train_videos_resized/train_16.mp4', './train_videos_resized/train_17.mp4', './train_videos_resized/train_18.mp4', './train_videos_resized/train_19.mp4', './train_videos_resized/train_20.mp4', './train_videos_resized/train_21.mp4', './train_videos_resized/train_22.mp4', './train_videos_resized/train_23.mp4', './train_videos_resized/train_24.mp4']\n",
      "['./train_annotations_resized/train_00.json', './train_annotations_resized/train_01.json', './train_annotations_resized/train_02.json', './train_annotations_resized/train_03.json', './train_annotations_resized/train_04.json', './train_annotations_resized/train_05.json', './train_annotations_resized/train_06.json', './train_annotations_resized/train_07.json', './train_annotations_resized/train_08.json', './train_annotations_resized/train_09.json', './train_annotations_resized/train_10.json', './train_annotations_resized/train_11.json', './train_annotations_resized/train_12.json', './train_annotations_resized/train_13.json', './train_annotations_resized/train_14.json', './train_annotations_resized/train_15.json', './train_annotations_resized/train_16.json', './train_annotations_resized/train_17.json', './train_annotations_resized/train_18.json', './train_annotations_resized/train_19.json', './train_annotations_resized/train_20.json', './train_annotations_resized/train_21.json', './train_annotations_resized/train_22.json', './train_annotations_resized/train_23.json', './train_annotations_resized/train_24.json']\n"
     ]
    }
   ],
   "source": [
    "# データ読込先のパスの設定\n",
    "train_videos = []\n",
    "train_annotations= []\n",
    "train_data_num = 25\n",
    "for index in range(train_data_num):\n",
    "    train_videos.append(\"./train_videos_resized/train_{:02}.mp4\".format(index)) # 読込先\n",
    "    train_annotations.append(\"./train_annotations_resized/train_{:02}.json\".format(index)) # 読込先\n",
    "print(train_videos)\n",
    "print(train_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2de79318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Car', 1: 'Bus', 2: 'Truck', 3: 'Svehicle', 4: 'Pedestrian', 5: 'Motorbike', 6: 'Bicycle', 7: 'Train', 8: 'Signal', 9: 'Signs'}\n"
     ]
    }
   ],
   "source": [
    "# カテゴリファイルの読み込みを行う\n",
    "categories_file = \"./docs/categories\" # カテゴリファイル。1行ごとにカテゴリ名が記載\n",
    "category_reader = CategoriesReader(categories_file)\n",
    "category_dict = category_reader.get_categories_dictionary()\n",
    "print(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72fc4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ保存先のパスの設定\n",
    "train_images_dir = \"./train_images\" # 画像データを保存するフォルダ\n",
    "train_label_file = os.path.join(train_images_dir, \"labels.txt\") # 教師データラベルを保存するファイル\n",
    "\n",
    "# データ保存先のフォルダが存在しなければ作成する\n",
    "if not os.path.exists(train_images_dir):\n",
    "    os.mkdir(train_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ccd29f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ext = \"jpg\" \n",
    "train_labels = []\n",
    "\n",
    "for video_path, annotation_path in zip(train_videos, train_annotations):\n",
    "    ### ①学習用動画データの画像をすべて読み込み、アノテーションデータも読み込みます。\n",
    "    # 学習用動画データ\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # アノテーションデータ\n",
    "    with open(annotation_path, 'r') as f:\n",
    "        train_annotations_json = json.load(f) # 辞書型に変換\n",
    "    \n",
    "    # ②読み込んだ1シーケンス分の画像データ配列(416x416x3)は、動画ファイル名(file_name)とシーケンス番号(sequense)をキーとして、画像ファイルとそのパス（image_path）を取得します。\n",
    "    sequence = 0\n",
    "    while True:\n",
    "        train_label_in_1seq = []\n",
    "        \n",
    "        # 動画から画像を1枚 読み込む\n",
    "        ret, frame = video.read()\n",
    "        if ret is False:\n",
    "            break\n",
    "            \n",
    "        # 保存先の画像ファイルのパスを取得\n",
    "        video_file_basename_without_ext = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        image_file_name = video_file_basename_without_ext + '_' + str(sequence) + '.' + ext\n",
    "        image_path = os.path.join(train_images_dir, image_file_name)\n",
    "        # 画像を保存する\n",
    "        cv2.imwrite(image_path, frame)\n",
    "        \n",
    "        # Jsonファイルからシーケンス番号に関連するground_truthの情報を読み込む\n",
    "        ground_truth_in_1seq = []\n",
    "        for categorical_number, category in category_dict.items():\n",
    "            category_values = train_annotations_json['sequence'][sequence].get(category)\n",
    "            if category_values is not None:\n",
    "                # 矩形を検出したら\n",
    "                for rect_info in category_values:\n",
    "                    ground_truth = []\n",
    "                    box2d = rect_info['box2d']\n",
    "                    # 矩形情報を保存する\n",
    "                    ground_truth.append(categorical_number)\n",
    "                    ground_truth.append(box2d[0])\n",
    "                    ground_truth.append(box2d[1])\n",
    "                    ground_truth.append(box2d[2])\n",
    "                    ground_truth.append(box2d[3])                    \n",
    "                    ground_truth_str = \",\".join([str(gt) for gt in ground_truth])\n",
    "                    ground_truth_in_1seq.append(ground_truth_str)\n",
    "        # 1シーケンス分の教師ラベルを取得\n",
    "\n",
    "        train_label_in_1seq.append(image_path)\n",
    "        [train_label_in_1seq.append(gt1seq) for gt1seq in ground_truth_in_1seq] \n",
    "        train_label_in_1seq_str = \" \".join(train_label_in_1seq)\n",
    "        train_labels.append(train_label_in_1seq_str)\n",
    "        sequence += 1\n",
    "    video.release()\n",
    "    # 全シーケンス分の教師ラベルを取得\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb3c7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 教師データラベルを保存する。\n",
    "#train_labels_str = \"\\n\".join(train_labels)\n",
    "with open(train_label_file, 'w') as f:\n",
    "    #f.write(train_labels_str)\n",
    "    for train_label in train_labels:\n",
    "        f.write(\"%s\\n\" % train_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a12fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
